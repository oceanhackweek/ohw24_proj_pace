{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d87afc4",
   "metadata": {},
   "source": [
    "# Orientation to Earthdata Cloud Access\n",
    "\n",
    "**Tutorial Lead:** Anna Windle (NASA, SSAI)\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "An [Earthdata Login][edl] account is required to access data from the NASA Earthdata system, including NASA ocean color data.\n",
    "\n",
    "</div>\n",
    "\n",
    "[edl]: https://urs.earthdata.nasa.gov/\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this example we will use the `earthaccess` package to search for\n",
    "OCI products on NASA Earthdata. The `earthaccess` package, published\n",
    "on the [Python Package Index][pypi] and [conda-forge][conda],\n",
    "facilitates discovery and use of all NASA Earth Science data\n",
    "products by providing an abstraction layer for NASAâ€™s [Common\n",
    "Metadata Repository (CMR) API][cmr] and by simplifying requests to\n",
    "NASA's [Earthdata Cloud][edcloud]. Searching for data is more\n",
    "approachable using `earthaccess` than low-level HTTP requests, and\n",
    "the same goes for S3 requests.\n",
    "\n",
    "In short, `earthaccess` helps **authenticate** with an Earthdata Login,\n",
    "makes **search** easier, and provides a stream-lined way to **load\n",
    "data** into `xarray` containers. For more on `earthaccess`, visit\n",
    "the [documentation][earthaccess-docs] site. Be aware that\n",
    "`earthaccess` is under active development.\n",
    "\n",
    "To understand the discussions below on downloading and opening data,\n",
    "we need to clearly understand **where our notebook is\n",
    "running**. There are three cases to distinguish:\n",
    "\n",
    "1. The notebook is running on the local host. For instance, you started a Jupyter server on your laptop.\n",
    "1. The notebook is running on a remote host, but it does not have direct access to the AWS us-west-2 region. For instance, you are running in [GitHub Codespaces][codespaces], which is run on Microsoft Azure. \n",
    "1. The notebook is running on a remote host that does have direct access to the NASA Earthdata Cloud (AWS us-west-2 region). This is the case for the PACE Hackweek. \n",
    "\n",
    "[pypi]: https://pypi.org/\n",
    "[conda]: https://oceancolor.gsfc.nasa.gov/resources/docs/tutorials/notebooks/oci-data-access/\n",
    "[cmr]: https://www.earthdata.nasa.gov/eosdis/science-system-description/eosdis-components/cmr\n",
    "[edcloud]: https://www.earthdata.nasa.gov/eosdis/cloud-evolution\n",
    "[earthaccess-docs]: https://earthaccess.readthedocs.io/en/latest/\n",
    "[codespaces]: https://github.com/features/codespaces\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "At the end of this notebook you will know:\n",
    "\n",
    "* How to store your NASA Earthdata Login credentials with `earthaccess`\n",
    "* How to use `earthaccess` to search for OCI data using search filters\n",
    "* How to download OCI data, but only when you need to\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Setup](#1.-Setup)\n",
    "2. [NASA Earthdata Authentication](#2.-NASA-Earthdata-Authentication)\n",
    "3. [Search for Data](#3.-Search-for-Data)\n",
    "4. [Open Data](#4.-Open-Data)\n",
    "5. [Download Data](#5.-Download-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1a0afa",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "We begin by importing the packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a94af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import xarray as xr\n",
    "from xarray.backends.api import open_datatree\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3539fd02",
   "metadata": {},
   "source": [
    "The last import provides a preview of the `DataTree` object. Once it is fully integrated into XArray,\n",
    "the additional import won't be needed, as the function will be available as `xr.open_datree`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2431d5e9",
   "metadata": {},
   "source": [
    "[back to top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3068e6",
   "metadata": {},
   "source": [
    "## 2. NASA Earthdata Authentication\n",
    "\n",
    "Next, we authenticate using our Earthdata Login\n",
    "credentials. Authentication is not needed to search publicaly\n",
    "available collections in Earthdata, but is always needed to access\n",
    "data. We can use the `login` method from the `earthaccess`\n",
    "package. This will create an authenticated session when we provide a\n",
    "valid Earthdata Login username and password. The `earthaccess`\n",
    "package will search for credentials defined by **environmental\n",
    "variables** or within a **.netrc** file saved in the home\n",
    "directory. If credentials are not found, an interactive prompt will\n",
    "allow you to input credentials.\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "    \n",
    "The `persist=True` argument ensures any discovered credentials are\n",
    "stored in a `.netrc` file, so the argument is not necessary (but\n",
    "it's also harmless) for subsequent calls to `earthaccess.login`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7810c2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = earthaccess.login(persist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081531a",
   "metadata": {},
   "source": [
    "[back to top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3586b4",
   "metadata": {},
   "source": [
    "## 3. Search for Data\n",
    "\n",
    "Collections on NASA Earthdata are discovered with the\n",
    "`search_datasets` function, which accepts an `instrument` filter as an\n",
    "easy way to get started. Each of the items in the list of\n",
    "collections returned has a \"short-name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d994722",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_datasets(instrument=\"oci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de385f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in results:\n",
    "    summary = item.summary()\n",
    "    print(summary[\"short-name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e959b217",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "The short name can also be found on <a href=\"https://search.earthdata.nasa.gov/search?fi=SPEXone!HARP2!OCI\" target=\"_blank\"> Eartdata Search</a>, directly under the collection name, after clicking on the \"i\" button for a collection in any search result.\n",
    "</div>\n",
    "\n",
    "Next, we use the `search_data` function to find granules within a\n",
    "collection. Let's use the `short_name` for the PACE/OCI Level-2 near real time (NRT), product for biogeochemical properties (although you can\n",
    "search for granules accross collections too).\n",
    "\n",
    "\n",
    "\n",
    "The `count` argument limits the number of granules whose metadata is returned and stored in the `results` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70f9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L2_BGC_NRT\",\n",
    "    count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc12d0",
   "metadata": {},
   "source": [
    "We can refine our search by passing more parameters that describe\n",
    "the spatiotemporal domain of our use case. Here, we use the\n",
    "`temporal` parameter to request a date range and the `bounding_box`\n",
    "parameter to request granules that intersect with a bounding box. We\n",
    "can even provide a `cloud_cover` threshold to limit files that have\n",
    "a lower percetnage of cloud cover. We do not provide a `count`, so\n",
    "we'll get all granules that satisfy the constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbc3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-07-01\", \"2024-07-31\")\n",
    "bbox = (-76.75, 36.97, -75.74, 39.01)\n",
    "clouds = (0, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf72a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L2_BGC_NRT\",\n",
    "    temporal=tspan,\n",
    "    bounding_box=bbox,\n",
    "    cloud_cover=clouds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b9c2d",
   "metadata": {},
   "source": [
    "Displaying results shows the direct download link: try it! The\n",
    "link will download one granule to your local machine, which may or\n",
    "may not be what you want to do. Even if you are running the notebook\n",
    "on a remote host, this download link will open a new browser tab or\n",
    "window and offer to save a file to your local machine. If you are\n",
    "running the notebook locally, this may be of use. However, in the\n",
    "next section we'll see how to download all the results with one\n",
    "command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3880c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2db9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d39b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c40086",
   "metadata": {},
   "source": [
    "[back to top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028332ad",
   "metadata": {},
   "source": [
    "## 4. Open L2 Data\n",
    "\n",
    "Let's go ahead and open a couple granules using `xarray`. The `earthaccess.open` function is used when you want to directly read bytes from a remote filesystem, but not download a whole file. When\n",
    "running code on a host with direct access to the NASA Earthdata\n",
    "Cloud, you don't need to download the data and `earthaccess.open`\n",
    "is the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f95c7",
   "metadata": {},
   "source": [
    "The `paths` list contains references to files on a remote filesystem. The ob-cumulus-prod-public is the S3 Bucket in AWS us-west-2 region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b803b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec22f2",
   "metadata": {},
   "source": [
    "Notice that this `xarray.Dataset` has nothing but \"Attributes\". The NetCDF data model includes multi-group hierarchies within a single file, where each group maps to an `xarray.Dataset`. The whole file maps to a `DataTree`, which we will only use lightly because the implementation in XArray remains under development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1122880c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datatree = open_datatree(paths[0])\n",
    "datatree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.merge(datatree.to_dict().values())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fe406",
   "metadata": {},
   "source": [
    "Let's do a quick plot of the `chlor_a` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9bf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = dataset[\"chlor_a\"].plot(vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34a0778",
   "metadata": {},
   "source": [
    "Let's plot with latitude and longitude so we can project the data onto a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0d941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.set_coords((\"longitude\", \"latitude\"))\n",
    "plot = dataset[\"chlor_a\"].plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmax=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c12302",
   "metadata": {},
   "source": [
    "And if we want to get fancy, we can add the coastline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b0f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.gridlines(draw_labels={\"left\": \"y\", \"bottom\": \"x\"})\n",
    "plot = dataset[\"chlor_a\"].plot(x=\"longitude\", y=\"latitude\", cmap=\"viridis\", vmax=5, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568a20f2",
   "metadata": {},
   "source": [
    "[back to top](#Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94009cc7",
   "metadata": {},
   "source": [
    "## 5. Open L3M Data\n",
    "\n",
    "Let's use `earthaccess` to open some L3 mapped chlorophyll a granules. We will use a new search filter available in earthaccess.search_data: the granule_name argument accepts strings with the \"*\" wildcard. We need this to distinguish daily (\"DAY\") from eight-day (\"8D\") composites, as well as to get the 0.1 degree resolution projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd969f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tspan = (\"2024-04-12\", \"2024-04-24\")\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L3M_CHL_NRT\",\n",
    "    temporal=tspan,\n",
    "    granule_name=\"*.DAY.*.0p1deg.*\",\n",
    ")\n",
    "\n",
    "paths = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c0819f",
   "metadata": {},
   "source": [
    "Let's open the first file using `xarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc814d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(paths[0])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc273979",
   "metadata": {},
   "source": [
    "Becuase the L3M variables have lat and lon coordinates, it's possible to stack multiple granules along a new dimension that corresponds to time. Instead of xr.open_dataset, we use xr.open_mfdataset to create a single xarray.Dataset (the \"mf\" in open_mfdataset stands for multiple files) from an array of paths.\n",
    "\n",
    "The paths list is sorted temporally by default, which means the shape of the paths array specifies the way we need to tile the files together into larger arrays. We specify combine=\"nested\" to combine the files according to the shape of the array of files (or file-like objects), even though paths is not a \"nested\" list in this case. The concat_dim=\"date\" argument generates a new dimension in the combined dataset, because \"date\" is not an existing dimension in the individual files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b05d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_mfdataset(\n",
    "    paths,\n",
    "    combine=\"nested\",\n",
    "    concat_dim=\"date\",\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb17702",
   "metadata": {},
   "source": [
    "A common reason to generate a single dataset from multiple, daily images is to create a composite. Compare the map from a single day ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0338891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chla = np.log10(dataset[\"chlor_a\"])\n",
    "chla.attrs.update(\n",
    "    {\n",
    "        \"units\": f'lg({dataset[\"chlor_a\"].attrs[\"units\"]})',\n",
    "    }\n",
    ")\n",
    "plot = chla.sel({\"date\": 0}).plot(aspect=2, size=4, cmap=\"GnBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333eca1",
   "metadata": {},
   "source": [
    "... to a map of average values, skipping \"NaN\" values that result from clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chla_avg = chla.mean(\"date\")\n",
    "chla_avg.attrs.update(\n",
    "    {\n",
    "        \"long_name\": chla.attrs[\"long_name\"],\n",
    "        \"units\": f'lg({chla.attrs[\"units\"]})',\n",
    "    }\n",
    ")\n",
    "plot = chla_avg.plot(aspect=2, size=4, cmap=\"GnBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae490b",
   "metadata": {},
   "source": [
    "## 6. Download Data\n",
    "\n",
    "Let's go ahead and download a couple granules. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc13a7",
   "metadata": {},
   "source": [
    "Let's look at the `earthaccess.download` function, which is used\n",
    "to copy files onto a filesystem local to the machine executing the\n",
    "code. For this function, provide the output of\n",
    "`earthaccess.search_data` along with a directory where `earthaccess` will store downloaded granules.\n",
    "\n",
    "Even if you only want to read a slice of the data, and downloading\n",
    "seems unncessary, if you use `earthaccess.open` while not running on a remote host with direct access to the NASA Earthdata Cloud,\n",
    "performance will be very poor. This is not a problem with \"the\n",
    "cloud\" or with `earthaccess`, it has to do with the data format and may soon be resolved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3573e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name=\"PACE_OCI_L2_BGC_NRT\",\n",
    "    temporal=tspan,\n",
    "    bounding_box=bbox,\n",
    "    cloud_cover=clouds,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb2b838",
   "metadata": {},
   "source": [
    "The `paths` list now contains paths to actual files on the local\n",
    "filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31edb1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = earthaccess.download(results, local_path=\"data\")\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c3fbe5",
   "metadata": {},
   "source": [
    "We can open up that locally saved file using `xarray` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ab44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_datatree(paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ac034d",
   "metadata": {},
   "source": [
    "[back to top](#Contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b356c512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
